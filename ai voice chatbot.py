import queue
import tempfile
import time
import os
import numpy as np
import pygame
import requests
import sounddevice as sd
import soundfile as sf
import whisper
from gtts import gTTS
import tkinter as tk
from tkinter import scrolledtext, ttk
import threading

# é…ç½®å‚æ•°
SAMPLE_RATE = 16000
CHUNK_DURATION = 3
OLLAMA_API_URL = "http://localhost:11434/api/chat"

# æ”¯æŒçš„è¯­è¨€
LANGUAGES = {
    "English": {
        "code": "en",
        "system_prompt": "You are a friendly English tutor. Respond concisely in under 100 words in English."
    },
    "Deutsch": {
        "code": "de",
        "system_prompt": "Du bist ein freundlicher Deutschlehrer. Antworte kurz und prÃ¤gnant in maximal 100 WÃ¶rtern auf Deutsch."
    },
    "ä¸­æ–‡": {
        "code": "zh",
        "system_prompt": "ä½ æ˜¯ä¸€ä½å‹å¥½çš„ä¸­æ–‡è€å¸ˆã€‚è¯·ç”¨100å­—ä»¥å†…çš„ä¸­æ–‡ç®€æ´å›ç­”ã€‚"
    }
}

# è¯­éŸ³æ£€æµ‹å‚æ•°
SILENCE_THRESHOLD = 0.015
MIN_SPEECH_DURATION = 0.3
MIN_SILENCE_DURATION = 0.8
PRE_SPEECH_BUFFER = 0.5

# åœ¨é…ç½®å‚æ•°éƒ¨åˆ†æ·»åŠ å¯ç”¨æ¨¡å‹åˆ—è¡¨
AVAILABLE_MODELS = {
    "Llama 3.1": "llama3.1",
    "DeepSeek-R1": "deepseek-R1"
}


class OllamaClient:
    def __init__(self, model_name="llama3.1"):
        self.model_name = model_name
        self.api_url = OLLAMA_API_URL

    def get_response(self, messages):
        payload = {
            "model": self.model_name,
            "messages": messages,
            "stream": False
        }

        try:
            response = requests.post(
                self.api_url,
                json=payload,
                timeout=30
            )

            if response.status_code == 200:
                response_data = response.json()
                return response_data['message']['content']
            else:
                print(f"Ollama API Error {response.status_code}: {response.text}")
                return None

        except Exception as e:
            print(f"Ollama API Request Failed: {str(e)}")
            return None


class VoiceChatbot:
    def __init__(self, root=None, model_name="llama3.1"):  # é»˜è®¤æ”¹ä¸º llama3.1
        # åˆå§‹åŒ–è¯­éŸ³æ¨¡å‹
        self.whisper_model = whisper.load_model("tiny")  # ä½¿ç”¨æ›´å°çš„æ¨¡å‹æé«˜é€Ÿåº¦

        # åˆå§‹åŒ–Ollamaå®¢æˆ·ç«¯
        self.llm_client = OllamaClient(model_name)

        # éŸ³é¢‘é˜Ÿåˆ—ç³»ç»Ÿ
        self.audio_queue = queue.Queue()
        self.response_queue = queue.Queue()

        # åˆå§‹åŒ–TTSå¼•æ“
        pygame.mixer.init()

        # å½“å‰è¯­è¨€è®¾ç½®
        self.current_language = "English"

        # å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†
        self.context = [
            {"role": "system", "content": LANGUAGES[self.current_language]["system_prompt"]}
        ]

        # çŠ¶æ€æ ‡å¿—
        self.is_recording = False
        self.is_playing = False
        self.recording_stream = None
        self.speech_detected = False
        self.ready_for_new_input = True

        # ä¸´æ—¶æ–‡ä»¶ç®¡ç†
        self.temp_dir = tempfile.mkdtemp()

        # UIç»„ä»¶
        self.root = root
        if self.root:
            self.setup_ui()

        # éŸ³é‡ç›‘æµ‹å˜é‡
        self.current_volume = 0

        # æ·»åŠ æ–°çš„æ§åˆ¶æ ‡å¿—
        self.processing_enabled = True

    def setup_ui(self):
        """è®¾ç½®GUIç•Œé¢"""
        self.root.title("Voice Chat Assistant")
        self.root.geometry("600x500")

        # æ·»åŠ æ¨¡å‹é€‰æ‹©
        self.model_frame = ttk.Frame(self.root)
        self.model_frame.pack(padx=10, pady=5, fill=tk.X)

        ttk.Label(self.model_frame, text="Model:").pack(side=tk.LEFT, padx=5)
        self.model_var = tk.StringVar(value="Llama 3.1")
        self.model_combo = ttk.Combobox(self.model_frame,
                                        textvariable=self.model_var,
                                        values=list(AVAILABLE_MODELS.keys()),
                                        state="readonly")
        self.model_combo.pack(side=tk.LEFT, padx=5)
        self.model_combo.bind('<<ComboboxSelected>>', self.change_model)

        # èŠå¤©è®°å½•åŒºåŸŸ
        self.chat_frame = ttk.Frame(self.root)
        self.chat_frame.pack(padx=10, pady=10, fill=tk.BOTH, expand=True)

        self.chat_display = scrolledtext.ScrolledText(self.chat_frame, wrap=tk.WORD, state=tk.DISABLED)
        self.chat_display.pack(fill=tk.BOTH, expand=True)

        # æ§åˆ¶åŒºåŸŸ
        self.control_frame = ttk.Frame(self.root)
        self.control_frame.pack(padx=10, pady=10, fill=tk.X)

        self.status_var = tk.StringVar(value="Ready")
        self.status_label = ttk.Label(self.control_frame, textvariable=self.status_var)
        self.status_label.pack(side=tk.LEFT, padx=5)

        self.record_button = ttk.Button(self.control_frame, text="Start Recording", command=self.toggle_recording)
        self.record_button.pack(side=tk.LEFT, padx=5)

        # éŸ³é‡æŒ‡ç¤ºå™¨
        self.volume_frame = ttk.Frame(self.root)
        self.volume_frame.pack(padx=10, pady=5, fill=tk.X)

        self.volume_meter = ttk.Progressbar(self.volume_frame, orient=tk.HORIZONTAL, length=200, mode='determinate')
        self.volume_meter.pack(side=tk.LEFT, padx=5, fill=tk.X, expand=True)

        # æ·»åŠ è¯­è¨€é€‰æ‹©
        self.lang_frame = ttk.Frame(self.root)
        self.lang_frame.pack(padx=10, pady=5, fill=tk.X)

        ttk.Label(self.lang_frame, text="Language:").pack(side=tk.LEFT, padx=5)
        self.language_var = tk.StringVar(value=self.current_language)
        self.language_combo = ttk.Combobox(self.lang_frame,
                                           textvariable=self.language_var,
                                           values=list(LANGUAGES.keys()),
                                           state="readonly")
        self.language_combo.pack(side=tk.LEFT, padx=5)
        self.language_combo.bind('<<ComboboxSelected>>', self.change_language)

        # å¯åŠ¨éŸ³é‡ç›‘æµ‹
        self.update_volume_meter()

    def update_volume_meter(self):
        """æ›´æ–°éŸ³é‡æŒ‡ç¤ºå™¨"""
        if self.is_recording:
            volume_percentage = min(100, int(self.current_volume * 100))
            self.volume_meter["value"] = volume_percentage
        else:
            self.volume_meter["value"] = 0

        self.root.after(100, self.update_volume_meter)

    def toggle_recording(self):
        """åˆ‡æ¢å½•éŸ³çŠ¶æ€"""
        if self.is_recording:
            self.stop_recording()
            self.record_button.config(text="Start Recording")
            self.status_var.set("Stopped recording")
        else:
            self.start_recording()
            self.record_button.config(text="Stop Recording")
            self.status_var.set("æ­£åœ¨è®¤çœŸå¬ä½ è¯´å‘¢...")

    def _recording_callback(self, indata, frames, time, status):
        """éŸ³é¢‘è¾“å…¥å›è°ƒå‡½æ•°"""
        if status:
            print(f"Recording error: {status}")

        volume = np.max(np.abs(indata))
        self.current_volume = volume * 2

        # åªæœ‰åœ¨å…è®¸å¤„ç†æ—¶æ‰æ·»åŠ åˆ°é˜Ÿåˆ—
        if self.processing_enabled and not self.is_playing:
            self.audio_queue.put((indata.copy(), volume))

    def start_recording(self):
        """å¯åŠ¨å½•éŸ³"""
        if self.is_recording:
            return

        print("\nğŸ¤ Recording started...")
        self.is_recording = True
        self.ready_for_new_input = True

        self.recording_stream = sd.InputStream(
            samplerate=SAMPLE_RATE,
            channels=1,
            callback=self._recording_callback,
            blocksize=int(SAMPLE_RATE * 0.1)
        )
        self.recording_stream.start()

        # å¯åŠ¨å¤„ç†çº¿ç¨‹
        self.processing_thread = threading.Thread(target=self.process_audio, daemon=True)
        self.processing_thread.start()

    def stop_recording(self):
        """åœæ­¢å½•éŸ³"""
        if not self.is_recording:
            return

        self.is_recording = False
        if self.recording_stream:
            self.recording_stream.stop()
            self.recording_stream.close()
            self.recording_stream = None

    def process_audio(self):
        """å¤„ç†éŸ³é¢‘é˜Ÿåˆ—"""
        accumulated_audio = []
        accumulated_time = 0
        speech_started = False
        speech_duration = 0
        silence_duration = 0

        while self.is_recording:
            try:
                # åªåœ¨å…è®¸å¤„ç†æ—¶è·å–éŸ³é¢‘
                if not self.processing_enabled:
                    time.sleep(0.1)
                    continue

                audio_chunk, volume = self.audio_queue.get(timeout=0.5)
                chunk_duration = len(audio_chunk) / SAMPLE_RATE
                accumulated_time += chunk_duration

                if volume > SILENCE_THRESHOLD:
                    if not speech_started and accumulated_time >= PRE_SPEECH_BUFFER:
                        speech_started = True
                        self.speech_detected = True

                    if speech_started:
                        speech_duration += chunk_duration
                        silence_duration = 0
                else:
                    if speech_started:
                        silence_duration += chunk_duration

                accumulated_audio.append(audio_chunk)

                should_process = (speech_started and
                                  speech_duration >= MIN_SPEECH_DURATION and
                                  silence_duration >= MIN_SILENCE_DURATION)

                if should_process:
                    self.process_accumulated_audio(accumulated_audio)
                    accumulated_audio = []
                    accumulated_time = 0
                    speech_started = False
                    speech_duration = 0
                    silence_duration = 0
                    self.speech_detected = False

            except queue.Empty:
                continue
            except Exception as e:
                print(f"Processing Error: {str(e)}")
                time.sleep(1)

    def process_accumulated_audio(self, audio_chunks):
        """å¤„ç†ç´¯ç§¯çš„éŸ³é¢‘æ•°æ®"""
        if not audio_chunks or not self.processing_enabled:
            return

        try:
            # æš‚æ—¶ç¦ç”¨å¤„ç†ä»¥é˜²æ­¢å½•å…¥AIå›ç­”
            self.processing_enabled = False

            # æ›´æ–°çŠ¶æ€ä¸ºè½¬å½•ä¸­
            if self.root:
                self.status_var.set("ä½ çš„å£°éŸ³æœ¬AIå¬å¾—ä¸€æ¸…äºŒæ¥š...")

            # ä½¿ç”¨æ›´å¿«çš„éŸ³é¢‘å¤„ç†
            audio_data = np.concatenate(audio_chunks)
            temp_file = os.path.join(self.temp_dir, "temp_audio.wav")
            sf.write(temp_file, audio_data, SAMPLE_RATE)

            # æ¸…ç©ºéŸ³é¢‘é˜Ÿåˆ—ï¼Œé˜²æ­¢å¤„ç†åˆ°AIçš„å›ç­”
            while not self.audio_queue.empty():
                self.audio_queue.get_nowait()

            # æ·»åŠ è¶…æ—¶æ§åˆ¶
            result = self.whisper_model.transcribe(
                temp_file,
                language=LANGUAGES[self.current_language]["code"],
                temperature=0.0,
                no_speech_threshold=0.3
            )
            user_text = result["text"].strip()

            if user_text:
                print(f"\nğŸ‘¤ User: {user_text}")
                if self.root:
                    self.update_chat_display("user", user_text)

                self.context.append({"role": "user", "content": user_text})

                # è·å–AIå“åº”
                ai_response = self.llm_client.get_response(self.context)

                if ai_response:
                    print(f"\nğŸ¤– AI: {ai_response}")
                    if self.root:
                        self.update_chat_display("assistant", ai_response)
                        self.status_var.set("å¸…æ°”å›ç­”ä¸­...")

                    self.context.append({"role": "assistant", "content": ai_response})

                    # æ–‡æœ¬è½¬è¯­éŸ³å¹¶æ’­æ”¾
                    self.text_to_speech(ai_response)

        except Exception as e:
            print(f"Error processing audio: {str(e)}")
            if self.root:
                self.status_var.set(f"Error: {str(e)}")
        finally:
            # é‡æ–°å¯ç”¨å¤„ç†
            self.processing_enabled = True
            # æ¢å¤å½•éŸ³çŠ¶æ€æ˜¾ç¤º
            if self.root and self.is_recording:
                self.status_var.set("æ­£åœ¨è®¤çœŸå¬ä½ è¯´å‘¢...")

    def text_to_speech(self, text):
        """æ–‡æœ¬è½¬è¯­éŸ³"""
        try:
            # ç¡®ä¿å¤„ç†è¢«ç¦ç”¨
            self.processing_enabled = False

            if self.root:
                self.status_var.set("å¤œä»¥ç»§æ—¥åœ°åŠ å·¥è¯­æ–™...")

            # æ¸…ç©ºéŸ³é¢‘é˜Ÿåˆ—
            while not self.audio_queue.empty():
                self.audio_queue.get_nowait()

            # ä½¿ç”¨gTTSç”Ÿæˆè¯­éŸ³
            response_file = os.path.join(self.temp_dir, "response.mp3")
            tts = gTTS(text=text, lang=LANGUAGES[self.current_language]["code"], slow=False)
            tts.save(response_file)

            self.is_playing = True

            if self.root:
                self.status_var.set("AIæ­£åœ¨å¸…æ°”å›ç­”...")

            # æ’­æ”¾éŸ³é¢‘
            pygame.mixer.music.load(response_file)
            pygame.mixer.music.play()

            # ç­‰å¾…æ’­æ”¾å®Œæˆ
            while pygame.mixer.music.get_busy():
                pygame.time.Clock().tick(10)

            time.sleep(0.5)  # æ·»åŠ çŸ­æš‚å»¶è¿Ÿ
            self.is_playing = False

            # å†æ¬¡æ¸…ç©ºéŸ³é¢‘é˜Ÿåˆ—
            while not self.audio_queue.empty():
                self.audio_queue.get_nowait()

        except Exception as e:
            print(f"TTS Error: {str(e)}")
            if self.root:
                self.status_var.set(f"TTS Error: {str(e)}")
        finally:
            self.is_playing = False
            # é‡æ–°å¯ç”¨å¤„ç†
            self.processing_enabled = True
            # æ¢å¤å½•éŸ³çŠ¶æ€æ˜¾ç¤º
            if self.root and self.is_recording:
                self.status_var.set("æ­£åœ¨è®¤çœŸå¬ä½ è¯´å‘¢...")

    def update_chat_display(self, speaker, text):
        """æ›´æ–°èŠå¤©æ˜¾ç¤º"""
        if not self.root:
            return

        self.chat_display.config(state=tk.NORMAL)

        if speaker == "user":
            self.chat_display.insert(tk.END, f"\nğŸ‘¤ You: {text}\n", "user")
        else:
            self.chat_display.insert(tk.END, f"\nğŸ¤– AI: {text}\n", "assistant")

        self.chat_display.tag_configure("user", foreground="#0000FF")
        self.chat_display.tag_configure("assistant", foreground="#FF0000")

        self.chat_display.config(state=tk.DISABLED)
        self.chat_display.see(tk.END)

    def change_language(self, event=None):
        """åˆ‡æ¢è¯­è¨€"""
        new_language = self.language_var.get()
        if new_language != self.current_language:
            self.current_language = new_language
            # æ›´æ–°ç³»ç»Ÿæç¤º
            self.context = [
                {"role": "system", "content": LANGUAGES[self.current_language]["system_prompt"]}
            ]
            if self.root:
                self.status_var.set(f"Language changed to {new_language}")
            print(f"Language changed to {new_language}")

    def change_model(self, event=None):
        """åˆ‡æ¢æ¨¡å‹"""
        selected_model = self.model_var.get()
        model_name = AVAILABLE_MODELS[selected_model]
        self.llm_client = OllamaClient(model_name)

        if self.root:
            self.status_var.set(f"Model changed to {selected_model}")
        print(f"Model changed to {selected_model}")

        # é‡ç½®å¯¹è¯ä¸Šä¸‹æ–‡
        self.context = [
            {"role": "system", "content": LANGUAGES[self.current_language]["system_prompt"]}
        ]

    def run(self):
        """è¿è¡Œä¸»ç¨‹åº"""
        if self.root:
            self.root.mainloop()
        else:
            try:
                self.start_recording()
                while True:
                    time.sleep(0.1)
            except KeyboardInterrupt:
                self.stop_recording()
                pygame.mixer.quit()


if __name__ == "__main__":
    try:
        root = tk.Tk()
        print("Starting Voice Chat Assistant (GUI Mode)...")
        chatbot = VoiceChatbot(root, model_name="llama3.1")  # è®¾ç½®é»˜è®¤æ¨¡å‹
        chatbot.run()
    except Exception as e:
        print(f"Error starting application: {str(e)}")
        print("Starting Voice Chat Assistant (Console Mode)...")
        chatbot = VoiceChatbot(model_name="llama3.1")  # è®¾ç½®é»˜è®¤æ¨¡å‹
        chatbot.run()
